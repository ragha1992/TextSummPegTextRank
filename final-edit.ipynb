{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7763796,"sourceType":"datasetVersion","datasetId":4540874},{"sourceId":7774953,"sourceType":"datasetVersion","datasetId":4548807}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-06T10:45:23.100464Z","iopub.execute_input":"2024-03-06T10:45:23.101206Z","iopub.status.idle":"2024-03-06T10:45:24.210369Z","shell.execute_reply.started":"2024-03-06T10:45:23.101175Z","shell.execute_reply":"2024-03-06T10:45:24.209422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install deepmultilingualpunctuation","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:45:24.212159Z","iopub.execute_input":"2024-03-06T10:45:24.212685Z","iopub.status.idle":"2024-03-06T10:45:38.059861Z","shell.execute_reply.started":"2024-03-06T10:45:24.212649Z","shell.execute_reply":"2024-03-06T10:45:38.058682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sumy","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:45:38.061789Z","iopub.execute_input":"2024-03-06T10:45:38.062075Z","iopub.status.idle":"2024-03-06T10:45:54.329786Z","shell.execute_reply.started":"2024-03-06T10:45:38.06205Z","shell.execute_reply":"2024-03-06T10:45:54.328863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nimport pandas as pd\nimport re\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import stopwords\nfrom gensim.models import Word2Vec\nfrom scipy import spatial\nimport networkx as nx","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:45:54.332475Z","iopub.execute_input":"2024-03-06T10:45:54.333151Z","iopub.status.idle":"2024-03-06T10:46:06.53496Z","shell.execute_reply.started":"2024-03-06T10:45:54.33312Z","shell.execute_reply":"2024-03-06T10:46:06.534208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sumy.parsers.plaintext import PlaintextParser\nfrom sumy.nlp.tokenizers import Tokenizer\nfrom sumy.summarizers.text_rank import TextRankSummarizer\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:46:06.536046Z","iopub.execute_input":"2024-03-06T10:46:06.536529Z","iopub.status.idle":"2024-03-06T10:46:06.558453Z","shell.execute_reply.started":"2024-03-06T10:46:06.536504Z","shell.execute_reply":"2024-03-06T10:46:06.5578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:46:06.559308Z","iopub.execute_input":"2024-03-06T10:46:06.559539Z","iopub.status.idle":"2024-03-06T10:46:25.356345Z","shell.execute_reply.started":"2024-03-06T10:46:06.559519Z","shell.execute_reply":"2024-03-06T10:46:25.355368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"load_locally\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:46:25.357589Z","iopub.execute_input":"2024-03-06T10:46:25.358385Z","iopub.status.idle":"2024-03-06T10:46:38.035199Z","shell.execute_reply.started":"2024-03-06T10:46:25.358357Z","shell.execute_reply":"2024-03-06T10:46:38.034382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def punctuate(text):\n    max_chunk_size = 1000\n    model = PunctuationModel()\n\n    def split_and_restore_punctuation(clean_text):\n        chunks = [clean_text[i:i+max_chunk_size] for i in range(0, len(clean_text), max_chunk_size)]\n        punctuated_chunks = []\n        for chunk in chunks:\n            result = model.restore_punctuation(chunk)\n            punctuated_chunks.append(result)\n        return ''.join(punctuated_chunks)\n\n    punctuated_text = split_and_restore_punctuation(text)\n    result = punctuated_text\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:48:01.574138Z","iopub.execute_input":"2024-03-06T10:48:01.575137Z","iopub.status.idle":"2024-03-06T10:48:01.581041Z","shell.execute_reply.started":"2024-03-06T10:48:01.575101Z","shell.execute_reply":"2024-03-06T10:48:01.580127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from deepmultilingualpunctuation import PunctuationModel","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:46:57.560979Z","iopub.execute_input":"2024-03-06T10:46:57.56132Z","iopub.status.idle":"2024-03-06T10:46:58.627827Z","shell.execute_reply.started":"2024-03-06T10:46:57.561295Z","shell.execute_reply":"2024-03-06T10:46:58.626873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chunk_sum(text_summary):\n    '''\n    tb\n    '''\n    model_name = \"load model locally\"\n    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n    model = PegasusForConditionalGeneration.from_pretrained(model_name)\n    chunk_size = 512  # Adjust the chunk size as needed\n    text_length = len(text_summary)\n    start = 0\n    gen_summ = \"\"\n\n    while start < text_length:\n        # Determine the end index of the current chunk\n        end = min(start + chunk_size, text_length)\n\n        # Extract the chunk of text\n        text_chunk = text_summary[start:end]\n\n        # Tokenize the chunk\n        input_ids = tokenizer(text_chunk, return_tensors=\"pt\").input_ids\n\n        # Generate the summary for the chunk\n        output = model.generate(\n          input_ids,\n          max_length=128,\n          num_beams=5,\n          early_stopping=True\n        )\n\n        # Decode and print the generated summary\n        gen_summ += \" \"+tokenizer.decode(output[0], skip_special_tokens=True)\n        #print(gen_summ)\n\n        # Move to the next chunk\n        start = end\n    return gen_summ\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:47:01.095072Z","iopub.execute_input":"2024-03-06T10:47:01.095433Z","iopub.status.idle":"2024-03-06T10:47:01.103807Z","shell.execute_reply.started":"2024-03-06T10:47:01.095404Z","shell.execute_reply":"2024-03-06T10:47:01.102703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sum_gen(text_to_summ):\n    clean_text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text_to_summ)\n    clean_text = re.sub('[^0-9a-zA-Z\\s.]+', ' ', clean_text)\n    result = punctuate(clean_text)\n\n    parser = PlaintextParser.from_string(result, Tokenizer('english'))\n    summarizer = TextRankSummarizer()\n    summary = summarizer(parser.document, 64)\n\n    text_summary = \"\"\n    for sentence in summary:\n        text_summary += str(sentence)\n    print(\"Commencing -->>\")\n    res1 = chunk_sum(text_summary)\n\n    return res1","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:47:01.911387Z","iopub.execute_input":"2024-03-06T10:47:01.912127Z","iopub.status.idle":"2024-03-06T10:47:01.918144Z","shell.execute_reply.started":"2024-03-06T10:47:01.912095Z","shell.execute_reply":"2024-03-06T10:47:01.917136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/apollohsp-ar/APOLLOHOSP_2015_Raw.txt\") as f:\n    lines = f.readlines()\nap_ip = ''\nfor line in lines:\n    ap_ip += line","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:47:03.394197Z","iopub.execute_input":"2024-03-06T10:47:03.394838Z","iopub.status.idle":"2024-03-06T10:47:03.428037Z","shell.execute_reply.started":"2024-03-06T10:47:03.394801Z","shell.execute_reply":"2024-03-06T10:47:03.427276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result15 = sum_gen(ap_ip)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T10:48:07.090874Z","iopub.execute_input":"2024-03-06T10:48:07.09177Z","iopub.status.idle":"2024-03-06T10:59:22.581543Z","shell.execute_reply.started":"2024-03-06T10:48:07.091736Z","shell.execute_reply":"2024-03-06T10:59:22.580756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(result15)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T11:00:05.115095Z","iopub.execute_input":"2024-03-06T11:00:05.11546Z","iopub.status.idle":"2024-03-06T11:00:05.122318Z","shell.execute_reply.started":"2024-03-06T11:00:05.115433Z","shell.execute_reply":"2024-03-06T11:00:05.121225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/apollohsp-ar/APOLLOHOSP_2016_Raw.txt\") as f:\n    lines = f.readlines()\nap_ip16 = ''\nfor line in lines:\n    ap_ip16 += line","metadata":{"execution":{"iopub.status.busy":"2024-03-06T11:02:33.50852Z","iopub.execute_input":"2024-03-06T11:02:33.50925Z","iopub.status.idle":"2024-03-06T11:02:33.531635Z","shell.execute_reply.started":"2024-03-06T11:02:33.509219Z","shell.execute_reply":"2024-03-06T11:02:33.530866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2024-03-06T11:03:20.693173Z","iopub.execute_input":"2024-03-06T11:03:20.693745Z","iopub.status.idle":"2024-03-06T11:03:20.69792Z","shell.execute_reply.started":"2024-03-06T11:03:20.693714Z","shell.execute_reply":"2024-03-06T11:03:20.696885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nresult16 = sum_gen(ap_ip16)\nend = time.time()\nprint(result16)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T11:03:22.311417Z","iopub.execute_input":"2024-03-06T11:03:22.312245Z","iopub.status.idle":"2024-03-06T11:14:42.83115Z","shell.execute_reply.started":"2024-03-06T11:03:22.31221Z","shell.execute_reply":"2024-03-06T11:14:42.830109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(end-start)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T11:14:42.832986Z","iopub.execute_input":"2024-03-06T11:14:42.83365Z","iopub.status.idle":"2024-03-06T11:14:42.83843Z","shell.execute_reply.started":"2024-03-06T11:14:42.833616Z","shell.execute_reply":"2024-03-06T11:14:42.837532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/apollohsp-ar/APOLLOHOSP_2017_Raw.txt\") as f:\n    lines = f.readlines()\nap_ip17 = ''\nfor line in lines:\n    ap_ip17 += line","metadata":{"execution":{"iopub.status.busy":"2024-03-06T11:14:42.839609Z","iopub.execute_input":"2024-03-06T11:14:42.840034Z","iopub.status.idle":"2024-03-06T11:14:42.89326Z","shell.execute_reply.started":"2024-03-06T11:14:42.840004Z","shell.execute_reply":"2024-03-06T11:14:42.892456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nresult17 = sum_gen(ap_ip17)\nend = time.time()\nprint(result17)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T11:14:42.894935Z","iopub.execute_input":"2024-03-06T11:14:42.895236Z"},"trusted":true},"execution_count":null,"outputs":[]}]}